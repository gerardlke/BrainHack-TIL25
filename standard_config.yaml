# environment configurations here
# seperate train and eval env
env:
  train:
    # rewards:
    num_vec_envs: 2
    env_type: 'binary'
    novice: True
    num_iters: 100
    eval_mode: True
    frame_stack_size: 4
    render_mode:


  eval:
    # rewards:
    num_vec_envs: 1
    env_type: 'normal'
    novice: True
    num_iters: 100
    eval_mode: True
    frame_stack_size: 1
    render_mode:


# the actual mapping from agents to policies is independent of policy configurations
# (will b handled in trainer)
policies:
  0:
    algorithm: ModifiedPPO
    policy: 'MlpPolicy'


  1: 
    algorithm: ModifiedPPO
    policy: 'MlpPolicy'


  
train:
  n_steps: 1000
  root_dir: '/mnt/e/BrainHack-TIL25'
  # all callbacks and their configurations here
  callbacks:


  # other training configurations
